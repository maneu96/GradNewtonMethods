# GradNewtonMethods
This was part of a project for the course Optimization and Algorithms at IST (2019/2020).
The challenge was to optimize the Log-regression cost function, using newton and gradient methods. Furthermore the algorithms were implemented with matricial calculations, so that the run-time would be as small as possible.
